{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from https://tfhub.dev/google/universal-sentence-encoder/2\n",
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "\n",
    "print(\"Loading model from {}\".format(module_url))\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embed Messages using Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "            \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "                \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "                    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding: [-0.016987282782793045, -0.008949815295636654, -0.0070627182722091675, ...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding: [0.03531332314014435, -0.025384284555912018, -0.007880025543272495, ...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding: [0.01879097707569599, 0.045365191996097565, -0.02001088112592697, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    " \n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "script_processed = open(\"script-processed\",'w')\n",
    "with open(\"script-raw\",'r') as script_raw:\n",
    "    for line in script_raw.readlines():\n",
    "        x = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", line)\n",
    "        x = x.strip()\n",
    "        script_processed.write(\"{}\\n\".format(x))\n",
    "script_processed.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get dialogues from script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Bus Driver, Stan Lee: What's the matter with you kids? You've never seen a spaceship before?\n",
      " Your Bus Driver, Stan Lee\n",
      "Your Bus Driver\n",
      "Child of Thanos:\n",
      " Child of Thanos\n",
      "Chung\n",
      "Tony Stark and Drax: Quill!\n",
      " Tony Stark and Drax\n",
      "Quill\n"
     ]
    }
   ],
   "source": [
    "chars = []\n",
    "file_handles = {}\n",
    "script = open(\"script-processed\",'r')\n",
    "for line in script.readlines():\n",
    "    line.strip()\n",
    "    if line==\"\":\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            character = line.split(\":\")[0]\n",
    "            newline = \" \".join(line.split(\":\")[1:])\n",
    "            if len(character.split())>2:\n",
    "                print(line,character)\n",
    "                input()\n",
    "            #print(line,character)\n",
    "            #input()\n",
    "            if character==\"\":\n",
    "                continue\n",
    "            elif character in chars:\n",
    "                file_handles[character].write(\"{}\\n\".format(newline.strip()))\n",
    "            else:\n",
    "                chars.append(character)\n",
    "                file_handles[character] = open(character+\".txt\",'w')\n",
    "                file_handles[character].write(\"{}\\n\".format(newline.strip()))\n",
    "        except:\n",
    "            print(\"Unknown error. Skipping line...\")\n",
    "\n",
    "#print(\"Files written for:\\n{}\".format(\"\\n\".join(chars)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting Similarity Matrix Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(corr,\\\n",
    "        #xticklabels=labels,\\\n",
    "        #yticklabels=labels,\\\n",
    "        vmin=0,\\\n",
    "        vmax=1,\\\n",
    "        cmap=\"YlOrRd\")\n",
    "    #g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "    #figure = g.get_figure()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Avenger-semantic-similarity.png\")\n",
    "    plt.show()\n",
    "\n",
    "def run_and_plot(session_, input_tensor_, messages_, labels_, encoding_tensor):\n",
    "    message_embeddings_ = session_.run(encoding_tensor, feed_dict={input_tensor_: messages_})\n",
    "    plot_similarity(labels_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Semantic Similarity Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from https://tfhub.dev/google/universal-sentence-encoder/2\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "\n",
    "print(\"Loading model from {}\".format(module_url))\n",
    "embed = hub.Module(module_url)\n",
    "file_path = \"./Avengers-Similarity-Analysis\"\n",
    "text_files = [os.path.join(file_path, f) for f in os.listdir(file_path) if f.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read these files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#characters = [i[:-4] for i in text_files]\n",
    "character_lines = {}\n",
    "\n",
    "print(\"Reading data from files...\")\n",
    "\n",
    "for fname in text_files:\n",
    "    character = fname[:-4]\n",
    "    print(\"Reading file for {}\".format(character))\n",
    "    character_line = \"\"\n",
    "    with open(fname,'r') as g:\n",
    "        for line in g.readlines():\n",
    "            character_line+=line.strip()\n",
    "        if character_line == \"\":\n",
    "            continue\n",
    "        character_lines[character]=character_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select characters\n",
    "print(\"================================\")\n",
    "print(\"Characters found:\")\n",
    "for i in range(len(character_lines.keys())):\n",
    "    print(\"{}: {}\".format(i,list(character_lines.keys())[i]))\n",
    "print(\"================================\")\n",
    "print(\"Enter character index to be used:\")\n",
    "print(\"Enter q or Q to stop.\")\n",
    "flag = True\n",
    "char_index = \"\"\n",
    "final_character_lines = {}\n",
    "characters = list(character_lines.keys())\n",
    "\n",
    "while flag:\n",
    "    char_index = input()\n",
    "    if char_index.upper() == 'Q':\n",
    "        flag=False\n",
    "    else:\n",
    "        char_index = int(char_index)\n",
    "        final_character_lines[characters[char_index]]=character_lines[characters[char_index]]\n",
    "\n",
    "# Index changed\n",
    "if flag == True:\n",
    "    character_lines = final_character_lines\n",
    "\n",
    "print(\"================================\")\n",
    "print(\"Characters selected:\")\n",
    "for i in range(len(character_lines.keys())):\n",
    "    print(\"{}: {}\".format(i,list(character_lines.keys())[i]))\n",
    "print(\"================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "similarity_message_encodings = embed(similarity_input_placeholder)\n",
    "#similarity_labels_placeholder= tf.placeholder(\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    run_and_plot(session, similarity_input_placeholder,\\\n",
    "            list(character_lines.values()),\\\n",
    "            list(character_lines.keys()),\\\n",
    "            similarity_message_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
